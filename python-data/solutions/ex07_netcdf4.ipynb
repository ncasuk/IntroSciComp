{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "4fc1b0c3-f3ec-4724-b24c-0e42bfdb2cb4",
   "metadata": {},
   "source": [
    "# Exercise 7: NetCDF4"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0ac81b88-7771-4404-89cd-d9ec233651d7",
   "metadata": {},
   "source": [
    "## Aim: Introduce the netCDF4 library in Python to read and create NetCDF4 Files."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b9de61d8-d634-4f06-b4d4-a1785fa3c6eb",
   "metadata": {},
   "source": [
    "### Issues covered:\n",
    "- Importing netCDF4\n",
    "- Reading a NetCDF file as a Dataset instance\n",
    "- Accessing dimensions, variables and attributes\n",
    "- Defining dimensions, variables and attributes\n",
    "- Writing a NetCDF file as a Dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "52089a6c-e341-4bd0-be15-72b1cace3aa8",
   "metadata": {},
   "source": [
    "## Creating/opening/closing netCDF files"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a47cb092-895b-411d-8ac2-2b7df0d1138d",
   "metadata": {},
   "source": [
    "- Import the `netCDF4` library\n",
    "- Let's create a new NetCDF file called \"test.nc\" in all? mode ('a') with the NETCDF4 format. This mode will allow us to edit the dataset later.\n",
    "- Inspect the new file to see what its `data_model` is."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "261f60af-c7ec-4cb3-8859-5d173a534a1d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 1: Import netCDF4 library\n",
    "import netCDF4\n",
    "# Step 2: Create the new file\n",
    "new_file = netCDF4.Dataset(\"test.nc\", \"a\", format=\"NETCDF4\")\n",
    "# Step 3: Check the new file out\n",
    "new_file.data_model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1c4e8491-204a-4bcf-9696-3535a37c7b8d",
   "metadata": {},
   "source": [
    "## Groups, dimensions, variables and attributes"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4649d782-c96b-4bc5-840b-231345ed4c79",
   "metadata": {},
   "source": [
    "### Groups"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c5ecfa40-dcd9-4728-aba7-57fef3dd089e",
   "metadata": {},
   "source": [
    "- Groups act as containers for variables, dimensions and attributes. Let's add a group to the dataset we just made called \"forecasts\".\n",
    "- List the groups of your dataset using `.groups`\n",
    "- Create a new group within forecasts called `model1` then print the groups to see your new group.\n",
    "- What happens if you do `group3 = new_file.createGroup(\"/analyses/model2\")`?\n",
    "- What happens if you do `group4 = new_file.createGroup(\"analyses\")`?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "6c3c7a16-5d5f-4f01-b83e-a20fe1c96392",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 1: \n",
    "group1 = new_file.createGroup(\"forecasts\")\n",
    "# Step 2: \n",
    "new_file.groups\n",
    "# Step 3: \n",
    "group2 = new_file.createGroup(\"/forecasts/model1\")\n",
    "new_file.groups\n",
    "# Step 4: \n",
    "# It creates the 'analyses' group then adds the 'model2' group to it.\n",
    "group3 = new_file.createGroup(\"/analyses/model2\")\n",
    "new_file.groups\n",
    "# Step 5: \n",
    "# Nothing - it returns the existing group.\n",
    "group4 = new_file.createGroup(\"analyses\")\n",
    "new_file.groups"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b898110e-14e8-464d-9a4f-bd19a273c7cb",
   "metadata": {},
   "source": [
    "### Dimensions"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4bdf87db-5455-45a2-ae47-22febfa0a20e",
   "metadata": {},
   "source": [
    "- Create some dimensions for the `new_file` dataset:\n",
    "    - time dimension with unlimited size\n",
    "    - level dimension with unlimited size\n",
    "    - lat dimension with unlimited size\n",
    "    - lon dimension with unlimited size\n",
    "- Print out the dimensions you just created.\n",
    "- Check the length of the latitude dimension to make sure it is 10.\n",
    "- Check that the level dimension is unlimited.\n",
    "- Let's take a look at an overview using \n",
    "```\n",
    "for dim in new_file.dimensions.values():\n",
    "    print(dim)\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "037ca268-58fa-4657-a527-112d08cc16b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 1:\n",
    "time = new_file.createDimension('time', None)\n",
    "level = new_file.createDimension('level', None)\n",
    "lat = new_file.createDimension('lat', None)\n",
    "lon = new_file.createDimension('lon', None)\n",
    "# Step 2:\n",
    "new_file.dimensions\n",
    "# Step 3: \n",
    "print(len(lat))\n",
    "# Step 4: \n",
    "print(level.isunlimited())\n",
    "# Step 5: \n",
    "for dim in new_file.dimensions.values():\n",
    "    print(dim)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "56511ca9-39a1-466a-9516-d801ab53407f",
   "metadata": {},
   "source": [
    "### Variables"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "68e7d217-ea7c-4ea2-af69-942239aebb29",
   "metadata": {},
   "source": [
    "Remember that the data types are as follows:\n",
    "- `f4`: 32-bit floting point \n",
    "- `f8`: 64-bit floating point \n",
    "- `i4`: 32-bit signed integer \n",
    "- `i2`: 16-bit signed integer\n",
    "- `i8`: 64-bit unsigned integer\n",
    "- `i1`: 8-bit signed integer\n",
    "- `u1`: 8-bit unsigned integer\n",
    "- `u2`: 16-bit unsigned integer\n",
    "- `u4`: 32-bit unsigned integer\n",
    "- `u8`: 64-bit unsigned integer\n",
    "- `S1`: single-character string"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1b7176b7-79b9-4e38-99f5-5491d91de3a2",
   "metadata": {},
   "source": [
    "- Create a scalar variable called `times` with the type set to `f8`.\n",
    "- Create a scalar variable called `levels` but this time set the type to `np.float64`. (You'll need to import nump as np)\n",
    "- Print out the variables using `new_file.variables`. What do you notice about the types?\n",
    "- Create a variable in the model2 group we made earlier called `temp`, with the float64 type and this time give it dimensions: (`time`, `level`, `lat`, `lon`). Print it out.\n",
    "- Create two values: \n",
    "    - longitudes with the name \"lon\", type float64 and dimension lon\n",
    "    - latitudes with the name \"lat\", type float64 and dimension lat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "292ca4fe-3681-4b5e-8b2e-c681a3aa9249",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 1:\n",
    "times = new_file.createVariable('times', 'f8')\n",
    "# Step 2: \n",
    "import numpy as np\n",
    "levels = new_file.createVariable('levels', np.float64)\n",
    "# Step 3:\n",
    "# The types are the same - both float64. Sometimes people will use np.float64 as it is more clear than f8. \n",
    "print(new_file.variables)\n",
    "# Step 4: \n",
    "temp = new_file.createVariable(\"/analyses/model2/temp\", np.float64, (\"time\", \"level\", \"lat\", \"lon\",))\n",
    "print(new_file.variables)\n",
    "# Step 5: \n",
    "longitudes = new_file.createVariable(\"lon\", np.float64, (\"lon\",))\n",
    "latitudes = new_file.createVariable(\"lat\", np.float64, (\"lat\",))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cf76552d-79d8-41c4-95fc-4616c02248b3",
   "metadata": {},
   "source": [
    "### Attributes"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0be859b4-16a3-48d0-9242-b8c590d8508a",
   "metadata": {},
   "source": [
    "- Let's create a global attribute. Create an attribute on the new_file object called `.description` with the value `This is a test description.`.\n",
    "- Let's create a variable attribute. Create an attribute on the `times` variable called `units` and put `hours`.\n",
    "- Take a look at the attrs on `new_file` using `new_file.ncattrs()`. What does this show?\n",
    "- To get the name AND description, use the following loop:\n",
    "```\n",
    "for name in new_file.ncattrs():\n",
    "    print(name, \":\", getattr(new_file, name))\n",
    "```\n",
    "- There is an easier way of doing this - using `new_file.__dict__`. Try it out!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "5ae8dcf6-0184-4f83-b75c-9684a852d140",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 1: \n",
    "new_file.description = \"This is a test description.\"\n",
    "# Step 2:\n",
    "times.units = \"hours\"\n",
    "# Step 3: \n",
    "#This just shows the name of the global attrs.\n",
    "new_file.ncattrs()\n",
    "# Step 4:\n",
    "for name in new_file.ncattrs():\n",
    "    print(name, \":\", getattr(new_file, name))\n",
    "# Step 5:\n",
    "new_file.__dict__"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "df7ec8fe-81b3-4768-9f4b-c643d4a8c254",
   "metadata": {},
   "source": [
    "## Writing data to and receiving data from netCDF variables"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d636cdaa-c646-406a-96e9-85810cea39ec",
   "metadata": {},
   "source": [
    "- Create an array to populate the lats with using `lats = np.arange(-100, 100, 2)` and an array to populate the lons with using `lons = np.arange(-200, 200, 2)`.\n",
    "- Print out latitudes and longitudes to see what it looks like before we populate these variables.\n",
    "- Populate the two variables with our data using `latitudes[:] = lats` and the same for longitudes.\n",
    "- Print the data out and take a look."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "f14444cf-ff2b-4b90-b4fd-3af73ad640b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 1: \n",
    "lats = np.arange(-90, 91, 5)\n",
    "lons = np.arange(-180, 180, 5)\n",
    "# Step 2: \n",
    "print(latitudes)\n",
    "print(longitudes)\n",
    "# Step 3: \n",
    "latitudes[:] = lats\n",
    "longitudes[:] = lons\n",
    "# Step 4: \n",
    "print(\"latitudes =\\n{}\".format(latitudes[:]))\n",
    "print(\"longitudes =\\n{}\".format(longitudes[:]))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ce5d22bf-d201-424e-babc-11d9d431f834",
   "metadata": {},
   "source": [
    "- Extend new_file to include dimensions for `time` and `pressure` where time is an unlimited dimension.\n",
    "- Define a 4D variable `temperature` with dimensions (time, pressure, latitude, longitude)\n",
    "- Generate random temperature data for a subset of time and pressure values and assign it to `temperature`. Use dimensions (10, 3, 37, 73) where `time` ranges from 0 to 9, `pressure` has three levels (850, 500 and 200 hPa).\n",
    "- After assigning the data, print the shape of the `temperature` variable."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "f4c4384f-a966-4615-a2da-77168568ae77",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "temp shape after adding data = (10, 10, 37, 72)\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "new_file.createDimension(\"pressure\", 10)\n",
    "\n",
    "temperature = new_file.createVariable(\"temperature\", \"f4\", (\"time\", \"pressure\", \"lat\", \"lon\",))\n",
    "\n",
    "nlats = len(new_file.dimensions[\"lat\"])\n",
    "nlons = len(new_file.dimensions[\"lon\"])\n",
    "\n",
    "temperature[0:10, 0:3, :, :] = np.random.uniform(size=(10, 3, nlats, nlons))\n",
    "\n",
    "print(\"temp shape after adding data = {}\".format(temperature.shape))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "12c17e3e-ad67-4c29-a426-e6390626ce25",
   "metadata": {},
   "source": [
    "- Define the `pressure` variable with values [1000, 850, 700, 500, 300, 250, 200, 150, 100, 50].\n",
    "- Populate the `pressure` variable in the netCDF dataset.\n",
    "- Use fancy indexing to slice the temoerature variable: select times 0, 2 and 4. Use pressure levels [850, 500, 200] and select only positive latitudes and longitudes.\n",
    "- Print the shape of the resulting subset array."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "769c08e7-6db7-4112-b49e-8003787b6882",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "shape of fancy temp slice = (5, 3, 18, 35)\n"
     ]
    }
   ],
   "source": [
    "pressure = new_file.createVariable(\"pressure\", \"f4\", (\"pressure\",))\n",
    "\n",
    "pressure[:] = [1000., 850., 700., 500., 300., 250., 200., 150., 100., 50.]\n",
    "\n",
    "temperature = new_file.variables[\"temperature\"]\n",
    "latitudes = new_file.variables[\"lat\"][:]\n",
    "longitudes = new_file.variables[\"lon\"][:]\n",
    "\n",
    "tempdat = temperature[::2, [1, 3, 6], latitudes > 0, longitudes > 0]\n",
    "print(\"shape of fancy temp slice = {}\".format(tempdat.shape))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5be3bbc0-5276-4696-9332-7a81e8fefeab",
   "metadata": {},
   "source": [
    "## Time-coordinates"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b5de27f8-2588-4709-9f2c-ce9c8329fa3d",
   "metadata": {},
   "source": [
    "Most metadata standards specify that time should be measured relative to a fixed date with units such as `hours since YY-MM-DD hh:mm:ss`. We can convert values to and from calendar dates using `num2date` and `date2num` from the `cftime` library. Two other helpful functions are `datetime` and `timedelta` from the `datetime` library."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a295c7b8-b375-4b0b-a798-9fcb4ee7bb21",
   "metadata": {},
   "source": [
    "- Let's generate a list of data and time values: create a list called `dates` containing date and time values, starting from January 1st 2022, and incrementing by 6 hours for a total of 5 entries. \n",
    "- Use `date2num` to convert your list of dates to numeric values using: `units=\"hours since 2022-01-01 00:00:00\"` amd `calendar=\"gregorian\"`. Store these in an array called `times`.\n",
    "- Print the numeric times values to confirm the numeric representation.\n",
    "- Use `num2date` to convert times back to datetime objects using the same units and calendar. Store these in a list called `converted_dates`\n",
    "- Print the converted dates to verify they match the original dates list. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "e0a5e051-9910-4871-be1d-aba109c6e768",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original dates: [datetime.datetime(2022, 1, 1, 0, 0), datetime.datetime(2022, 1, 1, 6, 0), datetime.datetime(2022, 1, 1, 12, 0), datetime.datetime(2022, 1, 1, 18, 0), datetime.datetime(2022, 1, 2, 0, 0)]\n",
      "Numeric time values (in units 'hours since 2022-01-01 00:00:00'):\n",
      "[ 0  6 12 18 24]\n",
      "Dates corresponding to numeric time values:\n",
      " [cftime.DatetimeGregorian(2022, 1, 1, 0, 0, 0, 0, has_year_zero=False)\n",
      " cftime.DatetimeGregorian(2022, 1, 1, 6, 0, 0, 0, has_year_zero=False)\n",
      " cftime.DatetimeGregorian(2022, 1, 1, 12, 0, 0, 0, has_year_zero=False)\n",
      " cftime.DatetimeGregorian(2022, 1, 1, 18, 0, 0, 0, has_year_zero=False)\n",
      " cftime.DatetimeGregorian(2022, 1, 2, 0, 0, 0, 0, has_year_zero=False)]\n"
     ]
    }
   ],
   "source": [
    "from datetime import datetime, timedelta\n",
    "from cftime import num2date, date2num\n",
    "\n",
    "# Step 1: Generate dates list\n",
    "dates = [datetime(2022, 1, 1) + n * timedelta(hours=6) for n in range(5)]\n",
    "print(\"Original dates:\", dates)\n",
    "\n",
    "# Step 2: Convert dates to numeric time values\n",
    "units = \"hours since 2022-01-01 00:00:00\"\n",
    "calendar = \"gregorian\"\n",
    "times = date2num(dates, units=units, calendar=calendar)\n",
    "\n",
    "# Step 3: Print numeric time values\n",
    "print(\"Numeric time values (in units '{}'):\\n{}\".format(units, times))\n",
    "\n",
    "# Step 4: Convert numeric time values back to calendar dates\n",
    "converted_dates = num2date(times, units=units, calendar=calendar)\n",
    "\n",
    "# Step 5: Print converted dates\n",
    "print(\"Dates corresponding to numeric time values:\\n\", converted_dates)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8264bcd2-1c62-4878-85b4-3589668de573",
   "metadata": {},
   "source": [
    "## Multi-file datasets"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "626c3848-99cf-4504-bce7-709159b527a6",
   "metadata": {},
   "source": [
    "Let's create multiple netCDF files with a shared variable and unlimited dimension, and use `MFDataset` to read the aggregated data as if it were contained in a single file.\n",
    "- Create 5 netCDF files named `datafile0.nc` through to `datafile4.nc`. Each file should contain:\n",
    "    - A single unlimited dimension named `time`.\n",
    "    - A variable named `temperature` with 10 integer values ranging from `file_index * 10` to `(file_index+1) * 10 - 1`.\n",
    "    - Ensure each file is saved in the `NETCDF4_CLASSIC` format.\n",
    "- Using `MFDataset` read all the `temperature` data from the 5 files at once by specifying a wildcard string `datafile*.nc`.\n",
    "- Print the aggregated `temperature` values to verify that they span from 0 to 49."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "5c893cff-a931-40a7-8b74-4b0df35a312c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14 15 16 17 18 19 20 21 22 23\n",
      " 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47\n",
      " 48 49]\n"
     ]
    }
   ],
   "source": [
    "from netCDF4 import Dataset, MFDataset\n",
    "import numpy as np\n",
    "\n",
    "# Step 1: Create multiple netCDF files with a shared unlimited dimension and variable\n",
    "for i in range(5):\n",
    "    with Dataset(f\"datafile{i}.nc\", \"w\", format=\"NETCDF4_CLASSIC\") as f:\n",
    "        # Create an unlimited dimension\n",
    "        f.createDimension(\"time\", None)\n",
    "        # Create a variable associated with the 'time' dimension\n",
    "        temp_var = f.createVariable(\"temperature\", \"i4\", (\"time\",))\n",
    "        # Populate 'temperature' with a unique range of values for each file\n",
    "        temp_var[:] = np.arange(i * 10, (i+1) * 10)\n",
    "\n",
    "# Step 2: Use MFDataset to read all files at once\n",
    "try:\n",
    "    #Read and aggregate all data across all files\n",
    "    f = MFDataset(\"datafile*.nc\")\n",
    "    temperature_data = f.variables[\"temperature\"][:]\n",
    "    # Print the aggregated data\n",
    "    print(temperature_data)\n",
    "finally:\n",
    "    # Close the MFDataset object\n",
    "    f.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b82b55e8-993d-49ab-bde8-d3a6cb383c03",
   "metadata": {},
   "source": [
    "## Compression of variables"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1c1e8875-86f1-46cf-b3f9-76f05bedf418",
   "metadata": {},
   "source": [
    "Let's explore various compression options available in netCDF. \n",
    "- Create a sample NetCDF file: define a dataset with dimensions (`time`, `level`, `lat`, `lon`)\n",
    "- Generate random temperature data.\n",
    "- First, create the temperature variable without compression and observe the file size.\n",
    "- Then, enable zlib compression and observe the change in file size.\n",
    "- Finally, add quantization with `least_significant_digit` or `signigicant_digits` and check the file size again."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "8d40143d-a204-4d8d-81aa-8ebe8bf50689",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "File size with compression=None, least_significant_digit=None, significant_digits=None: 983.31 kB\n",
      "File size with compression=zlib, least_significant_digit=None, significant_digits=None: 639.48 kB\n",
      "File size with compression=zlib, least_significant_digit=3, significant_digits=None: 505.94 kB\n",
      "File size with compression=zlib, least_significant_digit=None, significant_digits=4: 396.39 kB\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "\n",
    "# Step 1: Create a random dataset \n",
    "file_path = \"temperature_data.nc\"\n",
    "time_dim, level_dim, lat_dim, lon_dim = 10, 5, 50, 100\n",
    "data = np.random.rand(time_dim, level_dim, lat_dim, lon_dim) * 30 + 273.15\n",
    "\n",
    "# Step 2: Define a function to create netCDF file with specified compression settings\n",
    "def create_netcdf(file_path, compression=None, least_significant_digit=None, significant_digits=None):\n",
    "    with Dataset(file_path, 'w', format=\"NETCDF4\") as rootgrp:\n",
    "        # Create dimensions\n",
    "        rootgrp.createDimension(\"time\", time_dim)\n",
    "        rootgrp.createDimension(\"level\", level_dim)\n",
    "        rootgrp.createDimension(\"lat\", lat_dim)\n",
    "        rootgrp.createDimension(\"lon\", lon_dim)\n",
    "        # Define variable with compression settings\n",
    "        temp = rootgrp.createVariable(\"temp\", \"f4\", (\"time\", \"level\", \"lat\", \"lon\"), compression=compression, least_significant_digit=least_significant_digit, significant_digits=significant_digits)\n",
    "        #Assign data to the variable\n",
    "        temp[:] = data\n",
    "    # Check and print file size\n",
    "    print(f\"File size with compression={compression}, \"\n",
    "          f\"least_significant_digit={least_significant_digit}, \"\n",
    "          f\"significant_digits={significant_digits}: {os.path.getsize(file_path) / 1024:.2f} kB\")\n",
    "\n",
    "# Step 3: Test different compression settings\n",
    "# 3.1 No compression\n",
    "create_netcdf(\"temperature_data_nocompress.nc\")\n",
    "\n",
    "# 3.2 Compression with zlib only\n",
    "create_netcdf(\"temperature_data_zlib.nc\", compression='zlib')\n",
    "\n",
    "# 3.3 Compression with zlib and least significant digit quantization\n",
    "create_netcdf(\"temperature_data_zlib_lsd.nc\", compression='zlib', least_significant_digit=3)\n",
    "\n",
    "# 3.4 Compression with zlib and significant digits quantization\n",
    "create_netcdf(\"temperature_data_zlib_sig.nc\", compression='zlib', significant_digits=4)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dacc9cdd-87a1-4115-9300-718a96a7fec6",
   "metadata": {},
   "source": [
    "## Compound data types"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "669da898-5420-4c56-addf-13d9fac83bd3",
   "metadata": {},
   "source": [
    "Let's work with compound data types and structured arrays.\n",
    "- Create a netCDF file called `vectors.nc` in write mode.\n",
    "- Define a compound data type that represents a 3D vector. Each vector should have 3 components:\n",
    "    - `x`: a `float33` representing the x-coordinate\n",
    "    - `y`: a `float32` representing the y-coordinate\n",
    "    - `z`: a `float32` representing the z-coordinate\n",
    "- Create a dimension named `num_vectors` to store an unlimited number of vectors\n",
    "- Create a variable in the file using the compound data type from step 2, with the dimension from step 3.\n",
    "- Generate a numpy structured arrat with 5 sample 3D vectors:\n",
    "    - Each vector should have random values for `x`, `y` and `z` components.\n",
    "    - Store these in the structured array and write them to the netCDF variable.\n",
    "- Close the file and then reopen it in read mode.\n",
    "- Read the data back into a new numpy structured array and print each vector.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "4a5e899f-4a98-481d-bc8f-3a94b079b52d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Vector 0: (x: 0.42, y: 0.18, z: 0.29)\n",
      "Vector 1: (x: 0.24, y: 0.42, z: 0.55)\n",
      "Vector 2: (x: 0.34, y: 0.50, z: 0.46)\n",
      "Vector 3: (x: 0.42, y: 0.16, z: 0.68)\n",
      "Vector 4: (x: 0.71, y: 0.72, z: 0.03)\n"
     ]
    }
   ],
   "source": [
    "# Step 1: Create a netCDF file in write mode.\n",
    "f = Dataset(\"vectors.nc\", \"w\", format=\"NETCDF4\")\n",
    "\n",
    "# Step 2: Define a compound data type for a 3D vector with x,y,z as float32 fields\n",
    "vector_dtype = np.dtype([(\"x\", np.float32), (\"y\", np.float32), (\"z\", np.float32)])\n",
    "vector_t = f.createCompoundType(vector_dtype, \"vector3D\")\n",
    "\n",
    "# Step 3: Create a dimension for storing an unlimited number of vectors\n",
    "num_vectors = f.createDimension(\"num_vectors\", None)\n",
    "\n",
    "# Step 4: Create a variable using the compound data type and the dimension\n",
    "vector_var = f.createVariable(\"vector_data\", vector_t, (\"num_vectors\",))\n",
    "\n",
    "# Step 5: Generate a numpy structured array with 5 random 3D vectors\n",
    "num_samples = 5\n",
    "data = np.empty(num_samples, dtype=vector_dtype)\n",
    "data[\"x\"] = np.random.rand(num_samples)\n",
    "data[\"y\"] = np.random.rand(num_samples)\n",
    "data[\"z\"] = np.random.rand(num_samples)\n",
    "\n",
    "# Write the structured array to the netCDF variable\n",
    "vector_var[:] = data\n",
    "\n",
    "# Close the file\n",
    "f.close()\n",
    "\n",
    "#Step 6: Reopen the file in read-mode\n",
    "f = Dataset(\"vectors.nc\", \"r\")\n",
    "vector_var = f.variables[\"vector_data\"]\n",
    "\n",
    "# Step 7: Read the data back into a new structured array and print each vector\n",
    "data_in = vector_var[:]\n",
    "for i, vec in enumerate(data_in):\n",
    "    print(f\"Vector {i}: (x: {vec['x']:.2f}, y: {vec['y']:.2f}, z: {vec['z']:.2f})\")\n",
    "\n",
    "# Close the file\n",
    "f.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8d71f0a2-1f74-4274-99b9-4e3ca676851d",
   "metadata": {},
   "source": [
    "## Variable-length data types"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cac1a51b-6599-4917-b73a-2c35e8aacf55",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "7f5e9010-e996-47eb-8c22-4634388d7873",
   "metadata": {},
   "source": [
    "## Enum data type"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f3473edf-f46f-4301-b217-9b6e8f8d0fb5",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "6a042cb1-1db3-4eb6-9aba-5edd8bf05a84",
   "metadata": {},
   "source": [
    "## Extension"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b3d142c8-fc24-407d-8f8a-d87d932d3056",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 + Jaspy",
   "language": "python",
   "name": "jaspy"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
