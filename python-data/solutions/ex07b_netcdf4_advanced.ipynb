{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "22542fd5-6792-4df8-9122-fe35f3e4ddf5",
   "metadata": {},
   "source": [
    "# Exercise 7b: NetCDF4 Advanced"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b8bc8ade-8ef9-4caa-b734-d0a0df52a450",
   "metadata": {},
   "source": [
    "## Aim: Introduce more advanced uses of the netCDF4 library in Python to read and create NetCDF4 Files."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e92fc14e-6e03-49c3-99c1-7a7b1c2e52cf",
   "metadata": {},
   "source": [
    "Find the teaching material here: https://unidata.github.io/netcdf4-python/"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c2a56e34-d2ba-451d-900c-09e33c404e24",
   "metadata": {},
   "source": [
    "### Issues covered:\n",
    "- Working with time coordinates\n",
    "- Multi-file datasets\n",
    "- Compression of variables\n",
    "- Compound datatypes\n",
    "- Enum data type"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b9ba87e0-e96e-490d-a0a6-1da86bae8084",
   "metadata": {},
   "source": [
    "## Time-coordinates"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1c4acf3e-dc07-442e-a421-63efb78e0f79",
   "metadata": {},
   "source": [
    "Most metadata standards specify that time should be measured relative to a fixed date with units such as `hours since YY-MM-DD hh:mm:ss`. We can convert values to and from calendar dates using `num2date` and `date2num` from the `cftime` library. Two other helpful functions are `datetime` and `timedelta` from the `datetime` library."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2fecb97e-5775-4575-9739-9ad8cb7c3f97",
   "metadata": {},
   "source": [
    "Q1. \n",
    "- Let's generate a list of data and time values: create a list called `dates` containing date and time values, starting from January 1st 2022, and incrementing by 6 hours for a total of 5 entries. \n",
    "- Use `date2num` to convert your list of dates to numeric values using: `units=\"hours since 2022-01-01 00:00:00\"` amd `calendar=\"gregorian\"`. Store these in an array called `times`.\n",
    "- Print the numeric times values to confirm the numeric representation.\n",
    "- Use `num2date` to convert times back to datetime objects using the same units and calendar. Store these in a list called `converted_dates`\n",
    "- Print the converted dates to verify they match the original dates list. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "477bd19f-2833-4bb6-a2ae-83ebb7fc4a3d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original dates: [datetime.datetime(2022, 1, 1, 0, 0), datetime.datetime(2022, 1, 1, 6, 0), datetime.datetime(2022, 1, 1, 12, 0), datetime.datetime(2022, 1, 1, 18, 0), datetime.datetime(2022, 1, 2, 0, 0)]\n",
      "Numeric time values (in units 'hours since 2022-01-01 00:00:00'):\n",
      "[ 0  6 12 18 24]\n",
      "Dates corresponding to numeric time values:\n",
      " [cftime.DatetimeGregorian(2022, 1, 1, 0, 0, 0, 0, has_year_zero=False)\n",
      " cftime.DatetimeGregorian(2022, 1, 1, 6, 0, 0, 0, has_year_zero=False)\n",
      " cftime.DatetimeGregorian(2022, 1, 1, 12, 0, 0, 0, has_year_zero=False)\n",
      " cftime.DatetimeGregorian(2022, 1, 1, 18, 0, 0, 0, has_year_zero=False)\n",
      " cftime.DatetimeGregorian(2022, 1, 2, 0, 0, 0, 0, has_year_zero=False)]\n"
     ]
    }
   ],
   "source": [
    "from datetime import datetime, timedelta\n",
    "from cftime import num2date, date2num\n",
    "\n",
    "# Step 1: Generate dates list\n",
    "dates = [datetime(2022, 1, 1) + n * timedelta(hours=6) for n in range(5)]\n",
    "print(\"Original dates:\", dates)\n",
    "\n",
    "# Step 2: Convert dates to numeric time values\n",
    "units = \"hours since 2022-01-01 00:00:00\"\n",
    "calendar = \"gregorian\"\n",
    "times = date2num(dates, units=units, calendar=calendar)\n",
    "\n",
    "# Step 3: Print numeric time values\n",
    "print(\"Numeric time values (in units '{}'):\\n{}\".format(units, times))\n",
    "\n",
    "# Step 4: Convert numeric time values back to calendar dates\n",
    "converted_dates = num2date(times, units=units, calendar=calendar)\n",
    "\n",
    "# Step 5: Print converted dates\n",
    "print(\"Dates corresponding to numeric time values:\\n\", converted_dates)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7271d566-91d2-4d24-9213-39d6d28d2a0d",
   "metadata": {},
   "source": [
    "## Multi-file datasets"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "95cb2707-b27e-42ac-b80f-cf255b1a3c0f",
   "metadata": {},
   "source": [
    "Let's create multiple netCDF files with a shared variable and unlimited dimension, and use `MFDataset` to read the aggregated data as if it were contained in a single file.\n",
    "- Create 5 netCDF files named `data/datafile0.nc` through to `data/datafile4.nc`. Each file should contain:\n",
    "    - A single unlimited dimension named `time`.\n",
    "    - A variable named `temperature` with 10 integer values ranging from `file_index * 10` to `(file_index+1) * 10 - 1`.\n",
    "    - Ensure each file is saved in the `NETCDF4_CLASSIC` format.\n",
    "- Using `MFDataset` read all the `temperature` data from the 5 files at once by specifying a wildcard string `datafile*.nc`.\n",
    "- Print the aggregated `temperature` values to verify that they span from 0 to 49."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "3c6df18f-87e8-4051-a701-60d169656701",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14 15 16 17 18 19 20 21 22 23\n",
      " 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47\n",
      " 48 49]\n"
     ]
    }
   ],
   "source": [
    "from netCDF4 import Dataset, MFDataset\n",
    "import numpy as np\n",
    "\n",
    "# Step 1: Create multiple netCDF files with a shared unlimited dimension and variable\n",
    "for i in range(5):\n",
    "    with Dataset(f\"data/datafile{i}.nc\", \"w\", format=\"NETCDF4_CLASSIC\") as f:\n",
    "        # Create an unlimited dimension\n",
    "        f.createDimension(\"time\", None)\n",
    "        # Create a variable associated with the 'time' dimension\n",
    "        temp_var = f.createVariable(\"temperature\", \"i4\", (\"time\",))\n",
    "        # Populate 'temperature' with a unique range of values for each file\n",
    "        temp_var[:] = np.arange(i * 10, (i+1) * 10)\n",
    "\n",
    "# Step 2: Use MFDataset to read all files at once\n",
    "try:\n",
    "    #Read and aggregate all data across all files\n",
    "    f = MFDataset(\"datafile*.nc\")\n",
    "    temperature_data = f.variables[\"temperature\"][:]\n",
    "    # Print the aggregated data\n",
    "    print(temperature_data)\n",
    "finally:\n",
    "    # Close the MFDataset object\n",
    "    f.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "28e3eb27-a38b-4de7-beec-a04f95922561",
   "metadata": {},
   "source": [
    "## Compression of variables"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c2727e4a-5009-4678-b227-e40d49b576e6",
   "metadata": {},
   "source": [
    "Let's explore various compression options available in netCDF. \n",
    "- Create a sample NetCDF file: define a dataset with dimensions (`time`, `level`, `lat`, `lon`)\n",
    "- Generate random temperature data.\n",
    "- First, create the temperature variable without compression and observe the file size.\n",
    "- Then, enable zlib compression and observe the change in file size.\n",
    "- Finally, add quantization with `least_significant_digit` or `signigicant_digits` and check the file size again."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "73365563-9cf4-4b3b-9be8-c9814332b90a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "File size with compression=None, least_significant_digit=None, significant_digits=None: 983.31 kB\n",
      "File size with compression=zlib, least_significant_digit=None, significant_digits=None: 639.34 kB\n",
      "File size with compression=zlib, least_significant_digit=3, significant_digits=None: 505.77 kB\n",
      "File size with compression=zlib, least_significant_digit=None, significant_digits=4: 396.48 kB\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "\n",
    "# Step 1: Create a random dataset \n",
    "file_path = \"data/temperature_data.nc\"\n",
    "time_dim, level_dim, lat_dim, lon_dim = 10, 5, 50, 100\n",
    "data = np.random.rand(time_dim, level_dim, lat_dim, lon_dim) * 30 + 273.15\n",
    "\n",
    "# Step 2: Define a function to create netCDF file with specified compression settings\n",
    "def create_netcdf(file_path, compression=None, least_significant_digit=None, significant_digits=None):\n",
    "    with Dataset(file_path, 'w', format=\"NETCDF4\") as rootgrp:\n",
    "        # Create dimensions\n",
    "        rootgrp.createDimension(\"time\", time_dim)\n",
    "        rootgrp.createDimension(\"level\", level_dim)\n",
    "        rootgrp.createDimension(\"lat\", lat_dim)\n",
    "        rootgrp.createDimension(\"lon\", lon_dim)\n",
    "        # Define variable with compression settings\n",
    "        temp = rootgrp.createVariable(\"temp\", \"f4\", (\"time\", \"level\", \"lat\", \"lon\"), compression=compression, least_significant_digit=least_significant_digit, significant_digits=significant_digits)\n",
    "        #Assign data to the variable\n",
    "        temp[:] = data\n",
    "    # Check and print file size\n",
    "    print(f\"File size with compression={compression}, \"\n",
    "          f\"least_significant_digit={least_significant_digit}, \"\n",
    "          f\"significant_digits={significant_digits}: {os.path.getsize(file_path) / 1024:.2f} kB\")\n",
    "\n",
    "# Step 3: Test different compression settings\n",
    "# 3.1 No compression\n",
    "create_netcdf(\"data/temperature_data_nocompress.nc\")\n",
    "\n",
    "# 3.2 Compression with zlib only\n",
    "create_netcdf(\"data/temperature_data_zlib.nc\", compression='zlib')\n",
    "\n",
    "# 3.3 Compression with zlib and least significant digit quantization\n",
    "create_netcdf(\"data/temperature_data_zlib_lsd.nc\", compression='zlib', least_significant_digit=3)\n",
    "\n",
    "# 3.4 Compression with zlib and significant digits quantization\n",
    "create_netcdf(\"data/temperature_data_zlib_sig.nc\", compression='zlib', significant_digits=4)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "393a6184-658e-48fb-a10b-1c8d302bade6",
   "metadata": {},
   "source": [
    "## Compound data types"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "19c598d5-5d89-430e-9178-ec9cac5efe3f",
   "metadata": {},
   "source": [
    "Let's work with compound data types and structured arrays.\n",
    "- Create a netCDF file called `vectors.nc` in write mode.\n",
    "- Define a compound data type that represents a 3D vector. Each vector should have 3 components:\n",
    "    - `x`: a `float33` representing the x-coordinate\n",
    "    - `y`: a `float32` representing the y-coordinate\n",
    "    - `z`: a `float32` representing the z-coordinate\n",
    "- Create a dimension named `num_vectors` to store an unlimited number of vectors\n",
    "- Create a variable in the file using the compound data type from step 2, with the dimension from step 3.\n",
    "- Generate a numpy structured arrat with 5 sample 3D vectors:\n",
    "    - Each vector should have random values for `x`, `y` and `z` components.\n",
    "    - Store these in the structured array and write them to the netCDF variable.\n",
    "- Close the file and then reopen it in read mode.\n",
    "- Read the data back into a new numpy structured array and print each vector.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "c92e87db-f092-4802-a346-aaeb158b6395",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Vector 0: (x: 0.77, y: 0.94, z: 0.85)\n",
      "Vector 1: (x: 0.88, y: 0.60, z: 0.48)\n",
      "Vector 2: (x: 0.10, y: 0.05, z: 0.59)\n",
      "Vector 3: (x: 0.53, y: 0.26, z: 0.86)\n",
      "Vector 4: (x: 0.65, y: 0.37, z: 0.09)\n"
     ]
    }
   ],
   "source": [
    "# Step 1: Create a netCDF file in write mode.\n",
    "f = Dataset(\"data/vectors.nc\", \"w\", format=\"NETCDF4\")\n",
    "\n",
    "# Step 2: Define a compound data type for a 3D vector with x,y,z as float32 fields\n",
    "vector_dtype = np.dtype([(\"x\", np.float32), (\"y\", np.float32), (\"z\", np.float32)])\n",
    "vector_t = f.createCompoundType(vector_dtype, \"vector3D\")\n",
    "\n",
    "# Step 3: Create a dimension for storing an unlimited number of vectors\n",
    "num_vectors = f.createDimension(\"num_vectors\", None)\n",
    "\n",
    "# Step 4: Create a variable using the compound data type and the dimension\n",
    "vector_var = f.createVariable(\"vector_data\", vector_t, (\"num_vectors\",))\n",
    "\n",
    "# Step 5: Generate a numpy structured array with 5 random 3D vectors\n",
    "num_samples = 5\n",
    "data = np.empty(num_samples, dtype=vector_dtype)\n",
    "data[\"x\"] = np.random.rand(num_samples)\n",
    "data[\"y\"] = np.random.rand(num_samples)\n",
    "data[\"z\"] = np.random.rand(num_samples)\n",
    "\n",
    "# Write the structured array to the netCDF variable\n",
    "vector_var[:] = data\n",
    "\n",
    "# Close the file\n",
    "f.close()\n",
    "\n",
    "#Step 6: Reopen the file in read-mode\n",
    "f = Dataset(\"data/vectors.nc\", \"r\")\n",
    "vector_var = f.variables[\"vector_data\"]\n",
    "\n",
    "# Step 7: Read the data back into a new structured array and print each vector\n",
    "data_in = vector_var[:]\n",
    "for i, vec in enumerate(data_in):\n",
    "    print(f\"Vector {i}: (x: {vec['x']:.2f}, y: {vec['y']:.2f}, z: {vec['z']:.2f})\")\n",
    "\n",
    "# Close the file\n",
    "f.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1a537d6b-f892-444b-b63d-6bdbe4963e83",
   "metadata": {},
   "source": [
    "## Variable-length data types"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "faa9d0ba-0352-45bb-98cb-0443cecbc198",
   "metadata": {},
   "source": [
    "Let's create and manipulate variable-length (vlen) arrays\n",
    "- Create a netCDF file named `exercise_vlen.nc` in write mode.\n",
    "- Define dimensions:\n",
    "    - Create a dimension `a` with a size of `5`.\n",
    "    - Create a dimension `b` with a size of `4`.\n",
    "- Create a variable-length data type for signed 32-bit integers, named `my_vlen_int` using `np.int32` as the datatype.\n",
    "- Use the vlen type you defined to create a variable `vlen_var` with dimensions `(\"a\", \"b\")`. Populate `vlen_var` with random data:\n",
    "    - Each element should be a 1D numpy array of random length between 2 and 8.\n",
    "    - Each array element should contain random integers between 1 and 100. \n",
    "- Create a new dimension `c` with a size of `7`. Define a variable `vlen_str_var` along dimension `c`. Populate this variable with random strings of lengths between 3 and 10 using uppercase and lowercase alphabetic characters.\n",
    "- Print the contents of `vlen_var` and `vlen_str_var`. Print the structure of the netCDF4 file to show defined dimensions, variables, and data types."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "70ba5df2-e554-47de-b164-11d2c926f63d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Contents of 'vlen_var':\n",
      " [[array([82, 43, 68, 85, 90], dtype=int32)\n",
      "  array([29, 68, 23], dtype=int32) array([ 3, 53], dtype=int32)\n",
      "  array([61, 51,  5,  9, 78], dtype=int32)]\n",
      " [array([34, 96, 34, 82, 45, 56], dtype=int32)\n",
      "  array([70, 22, 96, 86], dtype=int32)\n",
      "  array([58, 90, 83, 69, 87, 63], dtype=int32)\n",
      "  array([39, 68, 95, 39, 11, 57, 13, 21], dtype=int32)]\n",
      " [array([98, 41, 39], dtype=int32) array([43, 37, 57], dtype=int32)\n",
      "  array([85, 84, 75, 25], dtype=int32)\n",
      "  array([68, 25, 87, 42, 24], dtype=int32)]\n",
      " [array([ 2, 72,  2, 60, 94, 20], dtype=int32)\n",
      "  array([41, 71, 21, 93, 60], dtype=int32)\n",
      "  array([69, 81, 68, 78], dtype=int32)\n",
      "  array([68, 13,  7, 90, 45, 59, 69, 89], dtype=int32)]\n",
      " [array([89, 33, 92, 88, 33, 38], dtype=int32)\n",
      "  array([ 4, 42, 82, 28,  2], dtype=int32)\n",
      "  array([98, 22, 64, 75,  3,  8, 75, 67], dtype=int32)\n",
      "  array([96, 38, 97,  7], dtype=int32)]]\n",
      "Contents of 'vlen_str_var':\n",
      " ['REulfoDs' 'BTx' 'pGqvr' 'dqYR' 'DjqTM' 'PAFCKNbi' 'niPqKWsLIh']\n",
      "\n",
      "NetCDF4 file structure:\n",
      " <class 'netCDF4._netCDF4.Dataset'>\n",
      "root group (NETCDF4 data model, file format HDF5):\n",
      "    dimensions(sizes): a(5), b(4), c(7)\n",
      "    variables(dimensions): int32 vlen_var(a, b), <class 'str'> vlen_str_var(c)\n",
      "    groups: \n",
      "Details of 'vlen_var':\n",
      " <class 'netCDF4._netCDF4.Variable'>\n",
      "vlen vlen_var(a, b)\n",
      "vlen data type: int32\n",
      "unlimited dimensions: \n",
      "current shape = (5, 4)\n",
      "Details of 'vlen_str_var':\n",
      " <class 'netCDF4._netCDF4.Variable'>\n",
      "vlen vlen_str_var(c)\n",
      "vlen data type: <class 'str'>\n",
      "unlimited dimensions: \n",
      "current shape = (7,)\n"
     ]
    }
   ],
   "source": [
    "import random\n",
    "import string\n",
    "\n",
    "# Step 1: Create a netCDF file in write mode\n",
    "f = Dataset(\"data/exercise_vlen.nc\", \"w\")\n",
    "\n",
    "# Step 2: Define dimensions a and b\n",
    "f.createDimension(\"a\", 5)\n",
    "f.createDimension(\"b\", 4)\n",
    "\n",
    "# Step 3: Create a variable-length data type for signed 32-bit integers\n",
    "vlen_int_type = f.createVLType(np.int32, \"my_vlen_int\")\n",
    "\n",
    "# Step 4: Create and populate the variable length integer array\n",
    "vlen_var = f.createVariable(\"vlen_var\", vlen_int_type, (\"a\", \"b\"))\n",
    "\n",
    "# Populate vlen_var with random-length integer arrays\n",
    "data = np.empty((5,4), dtype=object)\n",
    "for i in range(5):\n",
    "    for j in range(4):\n",
    "        random_length = random.randint(2, 8)\n",
    "        data[i,j] = np.random.randint(1, 101, size=random_length, dtype=np.int32)\n",
    "\n",
    "# Assign the data to the netCDF variable\n",
    "vlen_var[:, :] = data\n",
    "\n",
    "# Step 5: Create a dimension 'c' and define a variable-length string array\n",
    "f.createDimension(\"c\", 7)\n",
    "str_var = f.createVariable(\"vlen_str_var\", str, (\"c\",))\n",
    "\n",
    "# Populate vlen_str_var with random strings of lengths 3-10\n",
    "chars = string.ascii_letters\n",
    "string_data = np.empty(7, dtype=object)\n",
    "for i in range(7):\n",
    "    random_length = random.randint(3,10)\n",
    "    string_data[i] = ''.join(random.choice(chars) for _ in range(random_length))\n",
    "\n",
    "# Assign the string data to the netCDF variable\n",
    "str_var[:] = string_data\n",
    "\n",
    "# Step 6: Print the contents of \"vlen_var\" and \"vlen_str_var\"\n",
    "print(\"Contents of 'vlen_var':\\n\", vlen_var[:])\n",
    "print(\"Contents of 'vlen_str_var':\\n\", str_var[:])\n",
    "\n",
    "# Print the structure of the NetCDF4 file\n",
    "print(\"\\nNetCDF4 file structure:\\n\", f)\n",
    "print(\"Details of 'vlen_var':\\n\", f.variables[\"vlen_var\"])\n",
    "print(\"Details of 'vlen_str_var':\\n\", f.variables[\"vlen_str_var\"])\n",
    "\n",
    "# Close the file\n",
    "f.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "55abd572-29b3-47ea-9b9f-0e25364297d5",
   "metadata": {},
   "source": [
    "## Enum data type"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6f972a56-42e9-499c-ab1e-940b022c616a",
   "metadata": {},
   "source": [
    "Let's create a netCDF file to store weather observation data including an enumerated type representing different types of precipiation.\n",
    "- Create a Python dictionary `precip_dict` where:\n",
    "    - `None` maps to `0`\n",
    "    - `Rain` maps to `1`\n",
    "    - `Snow` maps to `2`\n",
    "    - `Sleet` maps to `3`\n",
    "    - `Hail` maps to `4`\n",
    "    - `Unknown` maps to `255`\n",
    "- Use this dictionary to define an Enum data type called `precip_t` with a base type of `np.uint8`\n",
    "- Define a dimension called `time` with an unlimited length for observations over time\n",
    "- Create a 1D variable named `precipitation` of type `precip_t` that uses the `time` dimension\n",
    "- Set the `fill_value` attribute of the variable to `255` (indicating missing data)\n",
    "- Write the following precipiatation observations to the `precipitation` variable: `['None', 'Rain', 'Snow', 'Unknown', 'Sleet']`\n",
    "- Close and reopen the file, then print the contents of the `precipitation` variable, inlcuding: the data values confirming they match the written values, the enum dictionary associated with the enum data type, verifying the precipitation mapping. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "f08fe449-acc3-41e3-bb36-3f6a2e63b98b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Enum dictionary: {'None': 0, 'Rain': 1, 'Snow': 2, 'Sleet': 3, 'Hail': 4, 'Unknown': 255}\n",
      "Precipitation data: [0 1 2 -- 3]\n"
     ]
    }
   ],
   "source": [
    "# Step 1: Create a new netCDF file\n",
    "nc = Dataset('data/weather_data.nc', 'w', format='NETCDF4')\n",
    "\n",
    "# Step 2: Define the Enum dictionary and create the Enum type\n",
    "precip_dict = {\n",
    "    'None': 0,\n",
    "    'Rain': 1,\n",
    "    'Snow': 2,\n",
    "    'Sleet': 3,\n",
    "    'Hail': 4,\n",
    "    'Unknown': 255\n",
    "}\n",
    "\n",
    "# Create an Enum type called 'precip_t' with base type uint8\n",
    "precip_type = nc.createEnumType(np.uint8, 'precip_t', precip_dict)\n",
    "\n",
    "# Step 3: Create a time dimension and variable using the Enum type\n",
    "nc.createDimension('time', None)  # unlimited dimension for time\n",
    "\n",
    "# Create the precipitation variable, setting the fill_value to 'Unknown' (255)\n",
    "precip_var = nc.createVariable('precipitation', precip_type, ('time',),\n",
    "                               fill_value=precip_dict['Unknown'])\n",
    "\n",
    "# Step 4: Write data to the variable\n",
    "precip_var[:] = [precip_dict[k] for k in ['None', 'Rain', 'Snow', 'Unknown', 'Sleet']]\n",
    "\n",
    "# Close the file\n",
    "nc.close()\n",
    "\n",
    "# Step 5: Reopen the file, read and print the data\n",
    "nc = Dataset('data/weather_data.nc', 'r')\n",
    "precip_var = nc.variables['precipitation']\n",
    "\n",
    "# Print the Enum dictionary\n",
    "print(\"Enum dictionary:\", precip_var.datatype.enum_dict)\n",
    "\n",
    "# Print the data stored in the variable\n",
    "print(\"Precipitation data:\", precip_var[:])\n",
    "\n",
    "# Close the file\n",
    "nc.close()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 + Jaspy",
   "language": "python",
   "name": "jaspy"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
